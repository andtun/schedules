{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Экспериментальная проверка полиномиальных алгоритмов\n",
    "Случаи сильно и слабо различающихся r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.polynomial.chebyshev as cheb\n",
    "from scipy.stats import moment\n",
    "from itertools import permutations\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display as pbdisplay\n",
    "from IPython.display import clear_output\n",
    "from scipy.interpolate import lagrange\n",
    "import shutil\n",
    "import sys\n",
    "import os.path\n",
    "from pyomo.environ import *\n",
    "from pyomo.gdp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 10\n",
    "MAXR = 1000\n",
    "MAXP = 1000\n",
    "MAXD = 10000\n",
    "\n",
    "def r(task):\n",
    "    ind = 0\n",
    "    if isinstance(task, TaskSet):\n",
    "        return task.array[ind]\n",
    "    return task[ind]\n",
    "\n",
    "def p(task):\n",
    "    ind = 1\n",
    "    if isinstance(task, TaskSet):\n",
    "        return task.array[ind]\n",
    "    return task[ind]\n",
    "\n",
    "def d(task):\n",
    "    ind = 2\n",
    "    if isinstance(task, TaskSet):\n",
    "        return task.array[ind]\n",
    "    return task[ind]\n",
    "\n",
    "def remove(arr, elem):\n",
    "    return np.delete(arr, np.where(np.in1d(arr, elem)))\n",
    "\n",
    "class TaskSet:\n",
    "    \n",
    "    def __init__(self, a):\n",
    "        if isinstance(a, int):\n",
    "            rs = np.random.randint(0, MAXR, size=(a,))\n",
    "            ps = np.random.randint(0, MAXP, size=(a,))\n",
    "            ds = np.random.randint(0, MAXD, size=(a,))\n",
    "            self.array = np.array([rs, ps, ds]).T.astype(float)\n",
    "        else:\n",
    "            self.array = np.copy(a)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"  r  |  p  |  d  \\n\" + str(self.array)\n",
    "    \n",
    "    def copy(self):\n",
    "        return TaskSet(self.array)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return TaskSet(self.array[key])\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.array)\n",
    "    \n",
    "    def C(self, i, tau=0):\n",
    "        t = tau\n",
    "        for task in self.array[:i+1]:\n",
    "            if t < r(task): t = r(task)\n",
    "            t += p(task)\n",
    "        return t\n",
    "    \n",
    "    def C_max(self, tau=0):\n",
    "        t = tau\n",
    "        for task in self.array:\n",
    "            if t < r(task): t = r(task)\n",
    "            t += p(task)\n",
    "        return t\n",
    "    \n",
    "    def L(self, i=None, tau=0):\n",
    "        if i is None:\n",
    "            return self.C_max(tau) - d(self[-1])\n",
    "        return self.C(i, tau) - d(self[i])\n",
    "    \n",
    "    def L_max(self, tau=0):\n",
    "        if len(self) == 0: return float('inf')\n",
    "        return max([self.L(i, tau) for i, _ in enumerate(self)])\n",
    "    \n",
    "    def T(self, i=None, tau=0):\n",
    "        return max(0, self.L(i, tau))\n",
    "    \n",
    "    def T_max(self, tau=0):\n",
    "        return max(0, self.L_max(tau))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.array)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.array == other\n",
    "    \n",
    "    def without(self, indexes):\n",
    "        return TaskSet(np.delete(self.array, np.array(indexes).astype(float), axis=0))\n",
    "    \n",
    "    def find(self, item):\n",
    "        return np.where((self.array == item).all(axis=1))[0]\n",
    "    \n",
    "    def transpose(self):\n",
    "        return self.array.T\n",
    "    \n",
    "    def scale_r(self, alpha):\n",
    "        self.array[:,0] = self.array[:,0]*alpha\n",
    "        return self\n",
    "    \n",
    "    def scale(self, alpha, key='r'):\n",
    "        if key == 'r': ind = 0\n",
    "        elif key == 'p': ind = 1\n",
    "        else: ind = 2\n",
    "        self.array[:,ind] = self.array[:,ind]*alpha\n",
    "        return self\n",
    "    \n",
    "def dual(N, tau, B):\n",
    "    if len(N.without(B)) == 0: return float('inf')\n",
    "    pi_r = r(np.argsort(N, axis=0).transpose())\n",
    "    bestL = N[pi_r].L(tau=tau)\n",
    "    for i_k in pi_r:\n",
    "        toDrop = B.copy()\n",
    "        toDrop.append(i_k)\n",
    "        #print(toDrop)\n",
    "        s = N.without(toDrop)\n",
    "        #print(s)\n",
    "        if len(s) != 0:\n",
    "            task_l = min(s, key=r)\n",
    "            i_l = N.find(task_l)[0]\n",
    "            pi_k = remove(pi_r, [i_l, i_k])\n",
    "            pi_k = np.insert(pi_k, 0, i_l)\n",
    "            pi_k = np.append(pi_k, i_k)\n",
    "            L_k = N[pi_k].L(tau=tau)\n",
    "            if L_k < bestL:\n",
    "                bestL = L_k\n",
    "    additionalL = N[pi_r].L(i=0, tau=tau)\n",
    "    if additionalL > bestL:\n",
    "        bestL = additionalL\n",
    "    return bestL\n",
    "\n",
    "class Instance:\n",
    "    \n",
    "    def __init__(self, N, tau=0, pi=[], B=[]):\n",
    "        self.N = N.copy()\n",
    "        self.tau = tau\n",
    "        self.pi = pi.copy()\n",
    "        self.B = B.copy()\n",
    "        self.nu = dual(N, tau, B)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        return TaskSet(self.N.array[key])\n",
    "        \n",
    "    def best_job(self):\n",
    "        s = self.N.without(self.B)\n",
    "        sn = s[r(s.transpose()) <= self.tau]\n",
    "        if len(sn) == 0:\n",
    "            f = min(s, key=r)\n",
    "            #self.tau = r(f)\n",
    "            #self.nu = dual(self.N, self.tau, self.B)\n",
    "        else:\n",
    "            f = min(sn, key=d)\n",
    "        return self.N.find(f)[0]\n",
    "    \n",
    "    def L(self, i=None):\n",
    "        return self[self.pi].L(i, self.tau)\n",
    "    \n",
    "    def T(self, i=None):\n",
    "        return self[self.pi].T(i, self.tau)\n",
    "        \n",
    "    def L_max(self):\n",
    "        return self[self.pi].L_max(self.tau)\n",
    "    \n",
    "    def T_max(self):\n",
    "        return self[self.pi].T_max(self.tau)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Instance:\\n\" + repr(self.N) + \"\\nnu  = \" + str(self.nu) + \"\\ntau = \" + str(self.tau) + \"\\npi  = \" + str(self.pi) + \"\\nB   = \" + str(self.B)\n",
    "    \n",
    "    \n",
    "def main(N, tau=0, verbose=False, modified=False):\n",
    "    tb = time.time()\n",
    "    b_counter = 0\n",
    "    #print(\"bi\")\n",
    "    instances = [Instance(N, tau)]\n",
    "    #print(\"ai\")\n",
    "    if modified: bestPi = list(range(len(N)))\n",
    "    else: bestPi = []\n",
    "    while len(instances) > 0:\n",
    "        ti = time.time()\n",
    "        if ti - tb > timeout:\n",
    "            return bestPi, -1\n",
    "        bestInstanceIndex, bestInstance = min(enumerate(instances), key=lambda x: x[1].nu) # + N[x[1].pi].L_max(tau))\n",
    "        instances.pop(bestInstanceIndex)\n",
    "        f = bestInstance.best_job()\n",
    "        f_data = bestInstance[f]\n",
    "        N1 = bestInstance.N.without(f)\n",
    "        tau1 = max(r(f_data), bestInstance.tau) + p(f_data)\n",
    "        B1 = []\n",
    "        pi1 = bestInstance.pi.copy()\n",
    "        pi1.append(N.find(f_data)[0])\n",
    "        i1 = Instance(N1, tau1, pi1, B1)\n",
    "        N2 = bestInstance.N\n",
    "        tau2 = bestInstance.tau\n",
    "        B2 = bestInstance.B.copy()\n",
    "        B2.append(N2.find(f_data)[0]) #!\n",
    "        pi2 = bestInstance.pi\n",
    "        i2 = Instance(N2, tau2, pi2, B2)\n",
    "        instances += [i1, i2]\n",
    "        b_counter += 1\n",
    "        #print(i1)\n",
    "        if len(pi1) == len(N):\n",
    "            #print(N[bestPi].L_max(tau))\n",
    "            #print(pi1)\n",
    "            if N[pi1].L_max(tau) < N[bestPi].L_max(tau):\n",
    "                bestPi = pi1.copy()\n",
    "                if verbose: print(bestPi, '\\tLmax =', N[bestPi].L_max(tau))\n",
    "        #lb = len(instances)\n",
    "        instances = [i for i in instances if i.nu < N[bestPi].L_max(tau)]\n",
    "        #print(lb, len(instances))\n",
    "    return bestPi, b_counter\n",
    "        \n",
    "def bruteforce(N, tau=0):\n",
    "    best_L = N.L_max(tau)\n",
    "    best_N = N.copy()\n",
    "    for perm in permutations(N):\n",
    "        s = TaskSet(perm)\n",
    "        L = s.L_max(tau)\n",
    "        if L < best_L:\n",
    "            best_L = L\n",
    "            best_N = s.copy()\n",
    "    return best_L, best_N\n",
    "\n",
    "def generate_instances(N_TASKS, N_JOBS, fname='data.pickle'):\n",
    "    tasks = []\n",
    "    for i in range(N_TASKS):\n",
    "        s = TaskSet(N_JOBS)\n",
    "        tasks.append(s)\n",
    "\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(tasks, f)\n",
    "        \n",
    "def parse_instances(fname='data.pickle'):\n",
    "    with open(fname, 'rb') as f:\n",
    "        tasks = pickle.load(f)\n",
    "    return tasks\n",
    "\n",
    "def simplex(s, verbose=True):\n",
    "    JOBS = s.array.copy()\n",
    "\n",
    "    t = dict()\n",
    "    for i, j in enumerate(JOBS):\n",
    "        t[str(i)] = {'r': j[0], 'p': j[1], 'd': j[2]}\n",
    "\n",
    "    JOBS = t\n",
    "    if verbose: print(JOBS)\n",
    "\n",
    "\n",
    "    def opt_schedule(JOBS):\n",
    "\n",
    "        # create model\n",
    "        m = ConcreteModel()\n",
    "\n",
    "        # index set to simplify notation\n",
    "        m.J = Set(initialize=JOBS.keys())\n",
    "        m.PAIRS = Set(initialize = m.J * m.J, dimen=2, filter=lambda m, j, k : j < k)\n",
    "\n",
    "        # upper bounds on how long it would take to process all jobs\n",
    "        tmax = max([JOBS[j]['r'] for j in m.J]) + sum([JOBS[j]['p'] for j in m.J])\n",
    "\n",
    "        # decision variables\n",
    "        m.start      = Var(m.J, domain=NonNegativeReals, bounds=(0, tmax))\n",
    "        m.pastdue    = Var(m.J, domain=NonNegativeReals, bounds=(0, tmax))\n",
    "        m.early      = Var(m.J, domain=NonNegativeReals, bounds=(0, tmax))\n",
    "        #m.x = Var(domain=NonNegativeReals, bounds=(0, tmax))\n",
    "        # additional decision variables for use in the objecive\n",
    "        m.makespan   = Var(domain=NonNegativeReals, bounds=(0, tmax))\n",
    "        m.maxpastdue = Var(domain=NonNegativeReals, bounds=(0, tmax), initialize=tmax)\n",
    "        m.ispastdue  = Var(m.J, domain=Binary)\n",
    "\n",
    "        # objective function\n",
    "        #m.OBJ = Objective(expr = sum([m.pastdue[j] for j in m.J]), sense = minimize)\n",
    "        m.OBJ = Objective(rule= lambda md: md.maxpastdue, sense = minimize)\n",
    "\n",
    "        # constraints\n",
    "        #m.c0 = Constraint(m.x == m.maxpastdue)\n",
    "        m.c1 = Constraint(m.J, rule=lambda m, j: m.start[j] >= JOBS[j]['r'])\n",
    "        m.c2 = Constraint(m.J, rule=lambda m, j: \n",
    "                m.start[j] + JOBS[j]['p'] + m.early[j] == JOBS[j]['d'] + m.pastdue[j])\n",
    "        m.c3 = Disjunction(m.PAIRS, rule=lambda m, j, k:\n",
    "            [m.start[j] + JOBS[j]['p'] <= m.start[k], \n",
    "             m.start[k] + JOBS[k]['p'] <= m.start[j]])    \n",
    "\n",
    "        m.c4 = Constraint(m.J, rule=lambda m, j: m.pastdue[j] <= m.maxpastdue)\n",
    "        m.c5 = Constraint(m.J, rule=lambda m, j: m.start[j] + JOBS[j]['p'] <= m.makespan)\n",
    "        m.c6 = Constraint(m.J, rule=lambda m, j: m.pastdue[j] <= tmax*m.ispastdue[j])\n",
    "\n",
    "        TransformationFactory('gdp.hull').apply_to(m)\n",
    "        if verbose:\n",
    "            SolverFactory('glpk').solve(m).write()\n",
    "        else:\n",
    "            SolverFactory('glpk').solve(m)\n",
    "\n",
    "        SCHEDULE = {}\n",
    "        for j in m.J:\n",
    "            SCHEDULE[j] = {'machine': 1, 'start': m.start[j](), 'finish': m.start[j]() + JOBS[j]['p']}\n",
    "\n",
    "        if verbose: print(SCHEDULE)\n",
    "        return SCHEDULE\n",
    "\n",
    "    SCHEDULE = opt_schedule(JOBS)\n",
    "    pi = list(map(int, sorted(SCHEDULE, key=lambda x: SCHEDULE[x]['start'])))\n",
    "    return pi\n",
    "\n",
    "def scale_timing(N_POINTS, FACTOR_MAX, N_TASKS, method='dual'):\n",
    "    \"\"\"\n",
    "    Available methods: dual, simplex\n",
    "    \"\"\"\n",
    "    pBar = IntProgress(min=0, max=N_POINTS**2, step=1)\n",
    "    pbdisplay(pBar)\n",
    "    results = np.zeros((N_POINTS, N_POINTS))\n",
    "    for n in range(N_TASKS):\n",
    "        pBar.value = 0\n",
    "        times = np.zeros((N_POINTS, N_POINTS))\n",
    "        s = tasks[n]\n",
    "        for factor_r in range(N_POINTS):\n",
    "            for factor_d in range(N_POINTS):\n",
    "                pBar.value += 1\n",
    "                scaled_s = s.copy().scale(FACTOR_MAX*factor_r/N_POINTS, key='r').scale(FACTOR_MAX*factor_d/N_POINTS, key='d')\n",
    "                tb = time.time()\n",
    "                if method == 'dual':\n",
    "                    sched, count = main(s)\n",
    "                elif method == 'simplex':\n",
    "                    sched = simplex(s, verbose=False)\n",
    "                times[factor_r, factor_d] = time.time() - tb\n",
    "        results = results + times\n",
    "    #results = results / N_TASKS\n",
    "    return results\n",
    "\n",
    "def heatmap(z, N_POINTS, FACTOR_MAX, N_TASKS, method='dual'):\n",
    "    y, x = np.meshgrid(np.linspace(0, FACTOR_MAX, N_POINTS), np.linspace(0, FACTOR_MAX, N_POINTS))\n",
    "    #print(x.shape, y.shape, z.shape)\n",
    "    # x and y are bounds, so z should be the value *inside* those bounds.\n",
    "    # Therefore, remove the last value from the z array.\n",
    "    z = z[:-1, :-1]\n",
    "    z_min, z_max = np.abs(z).min(), np.abs(z).max()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "    c = ax.pcolormesh(x, y, z, cmap='Blues', vmin=z_min, vmax=z_max)\n",
    "    #ax.set_title('pcolormesh')\n",
    "    # set the limits of the plot to the limits of the data\n",
    "    ax.axis([x.min(), x.max(), y.min(), y.max()])\n",
    "    ax.set_xlabel('α')\n",
    "    ax.set_ylabel('γ')\n",
    "    ax.set_title(\"%s tasks and %s*%s points with %s method\" % (N_TASKS, N_POINTS, N_POINTS, method))\n",
    "    fig.colorbar(c, ax=ax)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_heatmap(N_POINTS=15, FACTOR_MAX=1000, N_TASKS=5, method='dual'):\n",
    "    z = scale_timing(N_POINTS=15, FACTOR_MAX=1000, N_TASKS=5, method='dual')\n",
    "    heatmap(z, N_POINTS=15, FACTOR_MAX=1000, N_TASKS=5, method='dual')\n",
    "    fname = \"%spoints%smax%stasks%smethod.json\" % (N_POINTS, FACTOR_MAX, N_TASKS, method)\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(z, fname)\n",
    "        \n",
    "def lagrange_interpolation(key, s):\n",
    "    alphaRange = np.arange(0, 2.1, 0.2)\n",
    "    scaledSchedules = []\n",
    "    for alpha in alphaRange:\n",
    "        scaledSchedules.append(s.copy().scale(alpha, key=key))\n",
    "    flattenedScaledSchedules = list(map(lambda x: x.array.flatten(), scaledSchedules))\n",
    "\n",
    "    #print(\"\\rCurrently working with\", n)\n",
    "    approxResults = []\n",
    "    if len(alphaRange) != len(scaledSchedules): raise RuntimeError()\n",
    "    for i, a in enumerate(alphaRange):\n",
    "        if a != 1:\n",
    "            s = scaledSchedules[i]\n",
    "            sched, count = main(s, verbose=False)\n",
    "            if count == -1: continue\n",
    "            Lmax = s[sched].L_max()\n",
    "            approxResults.append((a, Lmax))\n",
    "    approxResults = np.array(approxResults)\n",
    "    if len(approxResults) == 0:\n",
    "        return float('inf')\n",
    "    x = approxResults[:,0]\n",
    "    y = approxResults[:,1]\n",
    "    #print(len(x))\n",
    "    #print(x, y)\n",
    "    poly = lagrange(x, y)\n",
    "    return poly(1.)\n",
    "\n",
    "def chebyshev_interpolation(k, schedule):\n",
    "    global realResult\n",
    "    global approxResults\n",
    "    global m\n",
    "    global s\n",
    "    global key\n",
    "    key = k\n",
    "    s = schedule\n",
    "\n",
    "    def test_schedule(alpha_arr):\n",
    "        global key\n",
    "        global approxResults\n",
    "        global m\n",
    "        global s\n",
    "        approxResults = []\n",
    "        for a in alpha_arr:\n",
    "            #print(\"\\ra =\", a, end='')\n",
    "            scaled_s = s.copy().scale(a, key=key)\n",
    "            #flattenedScaled_s = list(map(lambda x: x.array.flatten(), scaled_s))\n",
    "            bestPi, bestCounter = main(scaled_s, verbose=False)\n",
    "            Lmax = scaled_s[bestPi].L_max()\n",
    "            approxResults.append((a, Lmax))\n",
    "        approxResults = np.array(approxResults)\n",
    "        return approxResults[:,1]\n",
    "\n",
    "    \n",
    "    C = cheb.Chebyshev.interpolate(test_schedule, 13, [0, 2])\n",
    "    return C(1.)\n",
    "\n",
    "\n",
    "def mul_lagrange_interpolation(s):\n",
    "    N_POINTS = 10\n",
    "\n",
    "    delta_r = 0.1\n",
    "    delta_p = 0.2\n",
    "    delta_d = 0.05\n",
    "    N_TASKS = 3\n",
    "\n",
    "    scaledSchedules = []\n",
    "    alphaRange = []\n",
    "    #alphaRange.append(1.)\n",
    "    ticks = [(1.,1.,1.)]\n",
    "    for factor in range(N_POINTS):\n",
    "        factor_r = (5+factor)*delta_r\n",
    "        factor_p = factor*delta_p\n",
    "        factor_d = (15+factor)*delta_d\n",
    "        if factor_r != 1:\n",
    "            scaledSchedules.append(s.copy().scale(factor_r, key='r')\n",
    "                                   .scale(factor_p, key='p')\n",
    "                                   .scale(factor_d, key='d'))\n",
    "            alphaRange.append(factor_r)\n",
    "            ticks.append((round(factor_r,2),\n",
    "                      round(factor_p,2),\n",
    "                      round(factor_d,2)))\n",
    "    flattenedScaledSchedules = list(map(lambda x: x.array.flatten(), scaledSchedules))\n",
    "    #print(ticks)\n",
    "    #print(\"\\rCurrently working with\", n)\n",
    "    approxResults = []\n",
    "    if len(alphaRange) != len(scaledSchedules): raise RuntimeError()\n",
    "    for i, a in enumerate(alphaRange):\n",
    "        s = scaledSchedules[i]\n",
    "        sched, count = main(s, verbose=False)\n",
    "        if count == -1: continue\n",
    "        Lmax = s[sched].L_max()\n",
    "        #print(n, alphaRange[i], sched)\n",
    "        approxResults.append((a, Lmax))\n",
    "    approxResults = np.array(approxResults)\n",
    "    if len(approxResults) == 0:\n",
    "        return float('inf')\n",
    "    x = approxResults[:,0]\n",
    "    y = approxResults[:,1]\n",
    "    #print(len(x))\n",
    "    #print(x, y)\n",
    "    poly = lagrange(x, y)\n",
    "    return poly(1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получить случай сильно различающихся r\n",
    "def disperse(s):\n",
    "    coefs = np.zeros((len(s), len(s)))\n",
    "    for i in range(len(s)):\n",
    "        for j in range(i+1, len(s)):\n",
    "            i1 = s[i]\n",
    "            i2 = s[j]\n",
    "            if r(i1) > r(i2):\n",
    "                res = p(i2)/(r(i1)-r(i2))\n",
    "            else:\n",
    "                res = p(i1)/(r(i2)-r(i1))\n",
    "            coefs[i, j] = res\n",
    "    dalpha = np.ceil(coefs.max())\n",
    "    s_disperse = s.copy()\n",
    "    return s_disperse.scale(dalpha)\n",
    "\n",
    "# получить случай слабо различающихся r\n",
    "def ndisperse(s):\n",
    "    coefs = np.zeros((len(s), len(s)))\n",
    "    for i in range(len(s)):\n",
    "        for j in range(i+1, len(s)):\n",
    "            i1 = s[i]\n",
    "            i2 = s[j]\n",
    "            if r(i1) > r(i2):\n",
    "                res = p(i2)/(r(i1)-r(i2))\n",
    "            else:\n",
    "                res = p(i1)/(r(i2)-r(i1))\n",
    "            coefs[i, j] = res\n",
    "    ndalpha = coefs.min()\n",
    "    ndalpha = np.round(ndalpha, decimals=5)\n",
    "    s_ndisperse = s.copy()\n",
    "    return s_ndisperse.scale(ndalpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверить, что для примера определены полиномиальные области\n",
    "def check_polynomial(s):\n",
    "    return len(np.unique(s.array[:,0])) == len(s.array[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# решить случай сильно различающихся r\n",
    "def solve_disperse(s):\n",
    "    rs = list(map(r, s))\n",
    "    return np.argsort(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# решить случай слабо различающихся r\n",
    "def solve_ndisperse(s):\n",
    "    Lmax = np.inf\n",
    "    ds = list(map(d, s))\n",
    "    sortedpi = np.argsort(ds)\n",
    "    for index, item in enumerate(sortedpi):\n",
    "        deletedsortedpi = np.delete(sortedpi, index)\n",
    "        pi_i = np.hstack((item, deletedsortedpi))\n",
    "        curLmax = s[pi_i].L_max()\n",
    "        if curLmax < Lmax:\n",
    "            Lmax = curLmax\n",
    "            bestPi = pi_i.copy()\n",
    "    return bestPi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3186ebcff58f4c14849b898e70ddfb04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=1, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверено 100 примеров, полиномиальные алгоритмы нашли верное решение\n"
     ]
    }
   ],
   "source": [
    "N_TASKS = 100\n",
    "pBar = IntProgress(min=1, max=100, step=1)\n",
    "pbdisplay(pBar)\n",
    "i = 1\n",
    "while i != N_TASKS:\n",
    "    s = TaskSet(6)\n",
    "    if check_polynomial(s):\n",
    "        i += 1\n",
    "        pBar.value += 1\n",
    "        s_disperse = disperse(s)\n",
    "        pi_disperse = solve_disperse(s_disperse)\n",
    "        L_disperse = s_disperse[pi_disperse].L_max()\n",
    "        real_L_disperse, _ = bruteforce(s_disperse)\n",
    "\n",
    "        s_ndisperse = ndisperse(s)\n",
    "        pi_ndisperse = solve_ndisperse(s_ndisperse)\n",
    "        L_ndisperse = s_ndisperse[pi_ndisperse].L_max()\n",
    "        real_L_ndisperse, _ = bruteforce(s_ndisperse)\n",
    "\n",
    "        if L_disperse != real_L_disperse: raise RuntimeError()\n",
    "        if L_ndisperse != real_L_ndisperse: raise RuntimeError()\n",
    "print(\"Проверено %s примеров, полиномиальные алгоритмы нашли верное решение\" % i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
